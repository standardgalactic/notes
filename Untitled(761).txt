Femme Fractale: Lady in Red - Low-Complexity Art by Juergen Schmidhuber
How the Theory Explains Fun Through Learning Motor Skills. In many ways the laughs provoked by witty jokes are similar to those provoked by the acquisition of new skills through both babies and adults. Past the age of 25 JS learnt to juggle three balls. It was not a sudden process but an incremental and rewarding one: in the beginning he managed to juggle them for maybe one second before they fell down, then two seconds, four seconds, etc., until he was able to do it right. Watching himself in the mirror (as recommended by juggling teachers) he noticed an idiotic grin across his face whenever he made progress. Later his little daughter grinned just like that when she was able to stand on her own feet for the first time. All of this fits the theory perfectly: such grins are triggered by intrinsic reward for generating a data stream with previously unknown novel patterns, such as the sensory input sequence corresponding to observing oneself juggling, which may be quite different from the more familiar experience of observing somebody else juggling, and therefore truly novel and intrinsically rewarding, until the adaptive predictor / compressor (e.g., a recurrent neural network) gets used to it. Picture: iCub baby robot as used in JS' EU project IM-CLEVER on developmental robotics and on implementing the theory of fun & creativity on robots. (So far, however, the iCub has been unable to juggle the three balls for more than 60 seconds - much remains to be done.)

How the Theory Generalizes Active Learning (e.g., Fedorov, 1972). To optimize a function may require expensive data evaluations. Original active learning is limited to supervised classification tasks, asking which data points to evaluate next to maximize information gain, typically (but not necessarily) using 1 step look-ahead, assuming all data point evaluations are equally costly. The objective (to improve classification error) is given externally; there is no explicit intrinsic reward in the sense discussed here. The more general framework of creativity theory also takes formally into account: (1) Reinforcement learning agents embedded in an environment where there may be arbitrary delays between experimental actions and corresponding information gains, e.g., papers of 1991 & 1995, (2) The highly environment- dependent costs of obtaining or creating not just individual data points but data sequences of a priori unknown size, (3) Arbitrary algorithmic or statistical dependencies in sequences of actions & sensory inputs, e.g., papers of 2002 & 2006, (4) The computational cost of learning new skills, e.g., the 2002 paper here. Unlike previous approaches, these systems measure and maximize algorithmic novelty (learnable but previously unknown compressibility or predictability) of self-made, general, spatio- temporal patterns in the history of data and actions, e.g., papers 2006-2010.

No Objective Ideal Ratio Between Expected and Unexpected. Some of the previous attempts at explaining aesthetic experience in the context of math and information theory (Birkhoff 1933, Moles 1968, Bense 1969, Frank 1964, Nake 1974, Franke 1979) focused on the idea of an "ideal" ratio between expected and unexpected information conveyed by some aesthetic object (its order vs its complexity). Note that the alternative approach of JS does not have to postulate an objective ideal ratio of this kind. Instead his dynamic measure of interestingness reflects the change in the number of bits required to encode an object, and explicitly takes into account the subjective observer's prior knowledge as well as its limited compression improvement algorithm. Hence the value of an aesthetic experience is not defined by the observed object per se, but by the algorithmic compression progress of the subjective, learning observer