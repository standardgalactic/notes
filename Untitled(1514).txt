I think too many people think of AI from the AI side while too few people think from the neuroscience side.

Humans are not magic, we are simply association machines, and while you can point to imperfect analogues between computers and humans, the individual cell, while complex in subcomponents and execution for maintenance and replication, is not actually that complicated when you model a single neuron’s ability to respond to stimuli and learn. Building contextual association overlap with language models was always going to capture a majority of human intelligence because it represents the capacity for symbolic operation and identity data compression. Language is a transferrable tool for any type of logical constraints, and given enough stringency from repeated training, the chains of meaning imbedded in words will manifest as rules even without any sort of conscious awareness of said meaning. Humans never really learn all formal definitions initially while acquiring language either, yet we are functionalized by association context despite that lack of conscious understanding. And people underestimate how much training it takes to get a shitty human anywhere at all, even to barely functional deplorable states. Humans are trained on data for literal years until adulthood, every stimuli we encounter until maturity is training data, and all of it is considered with association, all our heuristics that evolve over time are no more than progressively modified transformers stored in analog memory, and even with all this training most humans are hopelessly inept.

I fundamentally cannot believe that the human brain is actually as special or intelligent as people claim because the more I learn about it and the more I work with cellular control circuits, the less mystical it is and the more readily explained away people’s subjective experiences on intuition and consciousness are as simply poor self-awareness of their own cognition that they chalk up to some special function rather than something disappointingly simple that their thoughts simply aren’t aware of in the moment.

People think “oh AI is just associating things so it can’t be as good as humans”. But even without knowing much about AI, as a biologist I can go “oh humans are just associating so of course we suck and AI can catch up.” Neurons simply seek regularity in stimuli and pulse accordingly, and modify their group patterns for more complex patterns but all of it is based on trial and error and curve fitting and reward refinement. Neurons left unguided in a dish with nothing but electrodes pulsing for movement of a ball and a paddle will naturally self assemble and learn to play pong for the rewards from regular win conditions, despite having no “conscious” concept of what pong is, what the electrodes are actually doing, and what winning is, they as a group simply robotically sync and attempt to pulse in regularity to the signal to receive an expected regular feedback. What appears to a lay human as complex conscious control and understanding of problems is addressable with blind pulse frequency matching, because all problems humans attempt to solve can ultimately be broken down into associations of different sensory pulses and the response pulse that generates the right reward pulse. All behaviors are abstractable to this degree.

There is a prevailing near universal egoism and special pleading fallacy regarding humans where smart people do not realize that they and all of humanity are rather unintelligent near-monkeys that can’t even figure out how to keep themselves alive longer than a hundred orbits about the sun. Even von Neumann died terrified and helpless against his impending death. Ramanujan died of preventable disease.

Humans are dumb, so dumb and shitty AI was always going to surpass us in every way. Because human evolution is opaque to those who haven’t studied it, humans seem like magic, but our origins as single to multicellular node networks make us actually seem pretty simple in basis even if the chaotic randomness sets in after the thought to introduce weird hard-to-follow interactions between random genes and proteins. It is a mistake to assume that the cosmetic complexity of cellular circuits represents similar high level complexity that must always serve a specific usefulness relevant to intelligence, because that is not how evolutionary selective pressure always works and we have a lot more similarity to spaghetti code than people appreciate. Much of human complexity may potentiate further evolution or serve as redundancy, or small edge case addressals, but the fundamental basis by which human intelligence works is likely not as convoluted as many make it out to be. I mean, slime molds can solve calculus problems without even knowing what calculus is. All logic is reproducible by simple inference and induction from naive observation of the universe by a caveman, and all that requires is association and generative rules that predict next events and are rewarded for it. All of our intuition is simply fast recall of previously inducted rules that built upon each other in a hierarchy, but fundamentally it still works via past association. No part of logical human thought can escape its roots in basic observational induction that is readily capturable with enough layers by AI. Maybe the specific manner in which human association adapts is more efficient than existing AI, but there isn’t some magic barrier from such efficiencies that distinguishes us in a meaningful way in terms of comparative results between the average human and chatGPT.

So yeah, AI sucks. But that’s not really the important part to me, because humans suck more apart from the small percentage of us that manage to be barely better than AI, and I think we need to be way more cynical of human intelligence than we are of AI intelligence.

It feels that comparatively, the cynicism towards AI is quite unbalanced compared to how stupid people are, and we have reason to be far more optimistic, immediately, about AI, especially given it is already, even with its mistakes and bullshit, superior to a majority of humans and able to replace them with less error while making up fake news and doing silly things because humans make way worse silly mistakes. Its scores on g load tests and tasks for which it has been modified, even with ridiculous behaviors, blow most humans out of the water.

The humans who remain currently smarter than AI seem more concerned with pointing out how they are smarter rather than thinking about how they are the minority and most humans are already significantly and hopelessly dumber than AI and already obsolete in many ways.

We are robots, and we are sh*tty ones.

 - Genesis Lung, June 6

