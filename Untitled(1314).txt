

As a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with, the contents by NLM or the National Institutes of Health.
Learn more: PMC Disclaimer | PMC Copyright Notice

￼

Biomimetics (Basel). 2023 Mar; 8(1): 110. 

Published online 2023 Mar 8. doi: 10.3390/biomimetics8010110

PMCID: PMC10046700

PMID: 36975340

There’s Plenty of Room Right Here: Biological Systems as Evolved, Overloaded, Multi-Scale Machines

Joshua Bongard1,†‡ and Michael Levin2,*†‡

Marc Weissburg, Academic Editor

Author information Article notes Copyright and License information PMC Disclaimer

Go to:

Abstract

The applicability of computational models to the biological world is an active topic of debate. We argue that a useful path forward results from abandoning hard boundaries between categories and adopting an observer-dependent, pragmatic view. Such a view dissolves the contingent dichotomies driven by human cognitive biases (e.g., a tendency to oversimplify) and prior technological limitations in favor of a more continuous view, necessitated by the study of evolution, developmental biology, and intelligent machines. Form and function are tightly entwined in nature, and in some cases, in robotics as well. Thus, efforts to re-shape living systems for biomedical or bioengineering purposes require prediction and control of their function at multiple scales. This is challenging for many reasons, one of which is that living systems perform multiple functions in the same place at the same time. We refer to this as “polycomputing”—the ability of the same substrate to simultaneously compute different things, and make those computational results available to different observers. This ability is an important way in which living things are a kind of computer, but not the familiar, linear, deterministic kind; rather, living things are computers in the broad sense of their computational materials, as reported in the rapidly growing physical computing literature. We argue that an observer-centered framework for the computations performed by evolved and designed systems will improve the understanding of mesoscale events, as it has already done at quantum and relativistic scales. To develop our understanding of how life performs polycomputing, and how it can be convinced to alter one or more of those functions, we can first create technologies that polycompute and learn how to alter their functions. Here, we review examples of biological and technological polycomputing, and develop the idea that the overloading of different functions on the same hardware is an important design principle that helps to understand and build both evolved and designed systems. Learning to hack existing polycomputing substrates, as well as to evolve and design new ones, will have massive impacts on regenerative medicine, robotics, and computer engineering.

Keywords: biology, computer science, robot, artificial life, artificial intelligence, machine learning, evolution

Go to:

1. Introduction

In Feynman’s famous lecture titled “There’s Plenty of Room at the Bottom” [1], he argued that vast technological progress could be achieved by learning to manipulate matter and energy at ever-smaller scales. Such potential could presumably be exploited by natural selection as well. How does biology expand the adaptive function of an existing system? It cannot go down, since there is already something there, exhibiting functional competencies at every level [2]. Instead, it squeezes more action from each level by overloading mechanisms with multiple functions—which we term as polycomputing. We argue that the most effective lens for a wide range of natural and engineered systems must enable a multiple-observers view where the same set of events can be interpreted as different computations (Figure 1 illustrates how artists have recognized this feature). Indeed, depending on their definition of computation, some human observers may conclude that the observed system is not computing at all.

￼

Figure 1

Polycomputing concepts in art. (A) Sculpture by Shigeo Fukuda, “Lunch with a helmet on”, 1987—appears as a random pile of knives and forks but when observed in just the right way, light moving through the sculpture reveals another pattern (a motorcycle) present at the same time in the same structure. (B) A well-known bistable (ambiguous) image, “My Wife and my Mother-in-Law” by British cartoonist William Ely Hill in 1915, reveals how our nervous system is not suited to taking in multiple meanings—it prefers to squash down to a single interpretation, even if it then has to vacillate back and forth.

Herein, we review remarkable examples of biological polycomputing, such as spider webs that serve as auditory sensors and prey capture devices [3], and holographic memory storage in the brain [4,5]. We will also review emerging examples in computer and materials engineering [6]. We provisionally define polycomputing as the ability of a material to provide the results of more than one computation in the same place at the same time. To distinguish this from complex materials that necessarily produce complex results in the same place at the same time, such as the multiple peaks in the frequency spectrum of a vibrating material, polycomputing must be embodied in a material that has been evolved, or can be designed to produce particular results—such as the results of particular mathematical transformations like digital logic—and must be readable by other parts of the material or other devices. That is, the computation, to be considered a computation, must be useful to one or more observers (which, in biology, can exist on multiple scales, with multiple subsystems from the molecular to the whole organism, or swarm levels being able to reap the diverse evolutionary benefits of a single process if they interpret it as processing information that provides an adaptive advantage). These ideas, which describe new ways of understanding and exploiting polycomputing in biology, may suggest ways to improve synthetic polycomputing systems, which, in turn, will shed light on the nature of computation, evolution, and control. Biological systems that polycompute also contribute to an ongoing conceptual debate within interdisciplinary science—the applicability of computer frameworks and metaphors to living systems [7]—in three ways. First: if polycomputing changes our understanding of what computation is, that might change whether we consider a living system to be a computer (Section 1.1). Second: a living system (or inorganic material) may be considered to be polycomputing, depending on one’s point of view, suggesting that observer dependence is unavoidable when considering whether or what a living or engineered system computes (Section 1.2). Third: increasingly intricate admixtures of technological and biological components that compute are forcing a redefinition of life itself (Section 1.3).

1.1. What Constitutes a Computer?

The notion of a “computer” needs to be expanded: it no longer only refers to the sequential, deterministic, silicon-embodied, human-programmed, von Neumann/Turing architectures with which biologists are familiar. Those are indeed dissimilar to living systems. There is now a widening array of computational substrates and robots that are often massively parallel (such as GPUs and computational metamaterials [8]), stochastic (hard to predict) [9], able to exploit non-obvious (and potentially not-yet-understood) properties of the exotic substrates they are built from [10], emergent, produced by evolutionary techniques [11], and built by other machines [12] or programmed by other algorithms [13,14,15]. The benefit of considering biological systems as members of this broader class is that it avails powerful conceptual frameworks from computer science to be deployed in biology in a deep way, and therefore to understand life far beyond its current limited use in computational biology. Moreover, exploring this powerful invariant between natural and synthetic systems can enrich intervention techniques within biology and improve the capabilities of engineered devices, revealing gaps in our understanding and the capabilities of both computer science and biology. Polycomputing is a powerful but, as of yet, under-appreciated example of the many ways in which the wider class of computer devices can help to revolutionize the life sciences. In the same way that organic and inorganic materials acting as computers increasingly challenges the claim that living materials are not computers, we have argued elsewhere [16] that the widening array of materials that can now be viewed or engineered with as machines is corroding the classic claim that living systems are not machines, and forcing an improved definition of “machine” that escapes the narrow definitions of past decades, which are no longer appropriate [17,18,19].

1.2. Observer Dependency

In the statement “living things are (or are not) computers”, “are” implies the existence of an objective, privileged view of both computers and biology that allows an unambiguous, universal decision as to whether they are related. This binary view is untenable and gives rise to numerous pseudo-problems. We argue instead for an observer-dependent view, in which computational formalisms are just metaphors; of course, all scientific concepts are just metaphors, with varying degrees of utility (which is not binary). Once we come to grips with the fact that “all models are wrong but some are useful” [20], it is possible to adopt a pragmatic approach [21] in which anything is a computer in a given context, to the degree to which it enables an observer to predict and control that thing better than any competing metaphors allow us to do. In this view, whether something is computing is not a philosophical question, but one to be settled experimentally by specifying a computational framework and showing empirically what new levels of capability, experiments, and research are enabled by adopting that framework. The only thing left is to enable system subcomponents, not just human scientists, to act as observers [22,23,24,25]. From that perspective, the quality of a computational metaphor in science is evidenced by its degree of productivity in new experimental capabilities, while the quality of a computational stance adopted by a biological subsystem is cashed out by the adaptive advantage that is evinced by it. Of course, it is expected that future progress will uncover even better frameworks, so the answer is never final, but always provisional and relative to a specific perspective. This view is akin both to the intentional stance in the philosophy of the mind [26], and in the driving of the development of frameworks and tools from cognitive science that can be broadly deployed across biology and the biomedical sciences [2,27,28].

1.3. What Things Are Alive?

Finally, the question of what constitutes a “living thing” is itself undergoing a renaissance due to the new chimeric, synthetic, and bioengineering techniques being developed [29]. Active matter, synthetic biology, and biohybrids [30,31,32,33,34,35,36] are blurring the line between evolved and designed systems, and dissolving the distinctions between “life” and “machine” [16,18,37], which were easy to maintain when our capabilities did not permit the construction and analysis of the full option space of agents [38,39]. At this point, the life sciences have expanded well beyond the N = 1 example of phylogenetic history here on Earth, to a clear mandate to understand life as it can be via synthetic and exobiological explorations [40,41,42,43,44,45,46].

1.4. From a Philosophy to a Science of How Life (Poly)Computes

We propose that the way to side-step philosophical debates about whether biological systems “are” computers is to adopt an observer-centered, scale-free view of the computational formalisms in biology. Polycomputing is an ideal example of a linking concept that will enrich both fields, which enables a number of fascinating questions with many fundamental and practical implications to be asked. What are the key functional and control properties of polycomputing systems? How does evolution create systems where multiple functions reside in the same hardware, and what does this design principle mean for evolvability? How can we derive intervention policies that make rational changes in existing polycomputing systems, and what are the efficient paths to the design of novel polycomputing materials, control algorithms, and device architectures?

Regardless of whether or not a living system is distally observed, it still polycomputes, because life itself adopts the same operator-dependent approach. In other words, a biological mechanism polycomputes because its functionality and signaling are interpreted in different ways by other components of that same living system. Each level and component of a living system are simultaneously observers and hackers, interpreting and taking advantage of different aspects of the mechanisms in their microenvironments, in parallel. Life polycomputes because it is a set of overlapping, competing, cooperating nested dolls, each of which is doing the best it can to predict and exploit its microenvironment [47,48,49,50,51,52,53].

1.5. Why “Life as Computation” Matters

The transfer of knowledge between the disciplines of biology and computation forms a positive feedback loop for increasing the insight within both. Biological examples help to widen the range of implementations for computing devices and provide novel ideas for architectures [54,55,56,57,58]; unconventional computing platforms include fungal networks, ant colonies, and DNA. In complement, computer science and its idea of functionalist substrate independence (multiple realizability) helps biologists to focus on essential, rather than contingent, design principles, expanding biology beyond zoology and botany. This has been most prevalent in neuroscience [59,60,61], but more recently has been extended far beyond it, in recognition of the fact that neural dynamics are only an extension of far older biological problem solving architectures [28,62,63,64].

A key conceptual insight from computer science that informs biology concerns the nature of computation. For example, the field of physical reservoir computing [65], in which a neural network is trained to map the dynamics occurring within an inorganic, biological, or technological system (the “reservoir”) into an output desired by a human observer, helps us to see the observer-dependent aspect of biology. This offers ways to think about biology as nested societies of elements which are exploiting the information-processing capacities [66] of their living environment. Cells, parasites, conspecifics, commensal organisms, and evolution itself are all hackers in the sense of using their parts and neighbors as affordances in whatever way they can, rather than in some single, unique, privileged, and objective way that reflects “true” functionality.

The concepts of superposition in quantum mechanics and the primacy of observer frames in relativity have transformed the understanding of this phenomena on very small and very large scales, respectively. Polycomputing challenges us to apply the same concepts to computation and life at mesoscales. Here, we overview the concepts of superposition and observer frames as they are applied to mesoscales and argue that the polycomputing lens, like the agential matter lens [67,68], helps us to understand, predict, and control new classes of evolved and designed materials, with numerous applications ranging from regenerative medicine to engineering.

Go to:

2. Current Debates: Dissolving Dichotomous Thinking

Whenever technological progress within a particular domain begins to slow, researchers often look to nature for fresh inspiration. Examples of this include the use of photosynthesis for new energy capture devices [69] and flapping wings for new drone designs [70]. Following this tradition, the increasing difficulty of packing more computing ability into microchips [71] challenges us to seek new paths forward by considering how computation is embedded within living systems. Comparing how organisms and machines compute requires one to view an organism as a kind of machine; otherwise, no comparison is possible. The debate about how or whether organisms are machines has a long history, and has become more intense in recent years [16,17,18,37,62,72,73], as various disciplines not only compare life to machines, but attempt to merge the two (reviewed in [38]).

Our usage of the term “machine” in what follows will denote a subset of machines that are capable of computation. Such machines include robots and physical computers but exclude simple mechanical devices such as combustion engines and flywheels, for which no way to stimulate or exploit them to produce computation has yet been invented (if such interventions are discovered, these technologies can then be considered as belonging more to the class of computational machines). In the spirit of our thesis, we acknowledge that there is no clear dividing line between these two “types” of machines, as circuitry-free machines such as mechanical computers, physical reservoir computers, [65] and computational metamaterials [8] can still compute. As always, there is a continuum: in this case, it is across machines capable of more or less computation. A possible exception may exist for machines that compute by exploiting quantum effects, although even there the notion of an observer plays a key role in deriving binary outcomes from a fundamentally indeterminate reality. The usage of the term “machine” rather than “computer” in what follows is meant to remind the reader that we are considering organisms vis-a-vis human-made things that compute, rather than just comparing them to traditional computers.

2.1. Structure Function Mapping and Polycomputing

An obvious starting point for the comparison between organisms and computers, or organisms and machines, is to assume a 1-to-1 mapping between the structure and function. A comparison can then be attempted between the organism’s and machine’s structures, and then between their functions. Finally, one can compare the structure-to-function mappings of the organisms and machines. However, teasing apart the structure and function for such comparisons is difficult. Genetics [74] and neuroscience [75] can both provide historical examples of how 1-to-1 structure/function mappings were rapidly replaced by models with increasingly dense and non-intuitive interactions between their structural and functional units. Even harder than making predictions based on this nontrivial structure-to-function mapping is inferring which interventions to make for rational changes at the system level, as is needed in the example of regenerative medicine—replacing complex organs such as hands and eyes [27,28]. Advances in other areas where biology and computer science meet are similarly demolishing these long held dichotomies (Table 1).

Indeed, an understanding of this wide range of implementations (materials, including organic components) and origin stories (e.g., evolutionary design techniques [76]) for machines makes it clear that, in many cases, a modern machine lens for life facilitates progress. The machine metaphor is a functional approach that seeks to develop possible efficient ways to predict, control, communicate with, and relate to a system and its reliable behavior modes. However, one aspect has lagged in both engineering and biology. It is relatively easy to see that technological or living components can support different functions at the same time but at different spatial scales: myosin, for example, supports muscle fiber contraction and legged locomotion simultaneously. It is also easy to see how components can support different functions on the same spatial scale but at different times: myosin can support legged locomotion and then tree climbing. However, it can be difficult to see how a component can provide multiple uses for multiple beneficiaries (or compute different functions from the vantage point of different observers) on the same spatial scale and at the same time. Investigating this last phenomenon—polycomputing—enables not only a new set of questions for biology, but also a quest for engineers to understand how to pack more functionality into the same machine.

